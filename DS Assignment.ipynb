{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5cfac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import  f1_score, confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630a0664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv file\n",
    "df = pd.read_csv('US_Heart_Patients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 10 rows:-\n",
    "print (df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43bf85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print 5-point summary:-\n",
    "print('5-point summary below as \\n')\n",
    "print (df.describe().loc[['min', '25%', '50%', '75%', 'max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83de1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the information regarding columns data type:-\n",
    "print ('data type of each column \\n')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f94f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of missing values in each column:-\n",
    "print ('number of missing values in each column \\n')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf36d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the correlations using heatmap:-\n",
    "\n",
    "correlation_matrix = df.corr(numeric_only=True)\n",
    "plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(correlation_matrix, xticklabels=correlation_matrix.columns,yticklabels=correlation_matrix.columns, annot=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876e2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data distributions using histogram:-\n",
    "\n",
    "df.hist(figsize=(10, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b00bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper methods for detecting the outliers for non categorical and non binary columns:-\n",
    "def get_non_categorical_columns():\n",
    "    return df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "def iqr_outlier(data):\n",
    "    q1 = data.quantile(0.25)\n",
    "    q3 = data.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    min = q1 - 1.5 * iqr\n",
    "    max = q3 + 1.5 * iqr\n",
    "    result = pd.Series([0] * len(data))\n",
    "    result[((data < min) | (data > max))] = 1\n",
    "    return sum(result)\n",
    "\n",
    "def check_column_is_binary(col):\n",
    "    if df[col].dropna().isin([0, 1]).all() and df[col].nunique() == 2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the number of outliers for non categorical and non binary columns:-\n",
    "outlier_columns = []\n",
    "non_categorical_columns = get_non_categorical_columns()\n",
    "\n",
    "def visualize_outliers():\n",
    "    plt.figure(figsize=(10,8))\n",
    "    i = 0\n",
    "    for col in non_categorical_columns:\n",
    "        if not check_column_is_binary(col):\n",
    "            plt.subplot(3, 4, i+1)\n",
    "            sns.boxplot(y=df[col])\n",
    "            i +=1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def print_and_visualize_outliers():\n",
    "    total_outliers = 0\n",
    "    for col in non_categorical_columns:\n",
    "        if not check_column_is_binary(col):\n",
    "            outliers =iqr_outlier(df[col])\n",
    "            if outliers ==0:\n",
    "                # print the columns where no outliers are presents\n",
    "                print(f'there is no outliers found in this column = {col}')\n",
    "            else:\n",
    "                print(f'total outliers found in this column = {col} is {outliers}')\n",
    "                outlier_columns.append(col)\n",
    "                total_outliers += outliers\n",
    "    print(f'total outliers are {total_outliers}')\n",
    "    visualize_outliers()\n",
    "print_and_visualize_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Data preprocessing steps:-\n",
    "\n",
    "# separate the categorical and non categorical columns to fill the missing value\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "non_categorical_columns = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# using mode to impute the categorical columns\n",
    "# using median to impute non categorical columns\n",
    "\n",
    "def imput_missing_values():\n",
    "     for col in categorical_columns:\n",
    "        df[col].fillna(df[col].mode().iloc[0], inplace=True)\n",
    "     for col in non_categorical_columns:\n",
    "          df[col].fillna(df[col].median(), inplace=True)\n",
    "            \n",
    "# treatment for the outliers\n",
    "def treat_outliers():\n",
    "    for column in outlier_columns:\n",
    "        median = df[column].median()\n",
    "        std_dev = df[column].std()\n",
    "        lower_limit = median - 2 * std_dev\n",
    "        upper_limit = median + 2 * std_dev\n",
    "        df[column] = np.where(df[column]> upper_limit, upper_limit, df[column])\n",
    "        df[column] = np.where(df[column]< lower_limit,lower_limit, df[column])\n",
    "    # print and visualize outliers:-\n",
    "    print_and_visualize_outliers()\n",
    "    \n",
    "# encode categorical columns using OneHotEncoder\n",
    "def encode():\n",
    "      #Initialize OneHotEncoder instance\n",
    "      encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "      # Apply one-hot encoding to the categorical columns\n",
    "      one_hot_encoded = encoder.fit_transform((df[categorical_columns]))\n",
    "      one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "      # Concatenate the one-hot encoded dataframe with the original dataframe\n",
    "      newdf = pd.concat([df, one_hot_df], axis=1)\n",
    "       # Drop the original categorical columns\n",
    "      newdf = newdf.drop(categorical_columns, axis=1)\n",
    "      return newdf\n",
    "    \n",
    "def data_processing():\n",
    "     # Impute the missing values\n",
    "     imput_missing_values()\n",
    "     # outliers treatment\n",
    "     treat_outliers()\n",
    "     # Encode categorical features\n",
    "     return encode()\n",
    "\n",
    "df = data_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afdb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra processing to remove outliers for the gulcose column\n",
    "lower_limit = df['glucose'].quantile(0.25)\n",
    "upper_limit = df['glucose'].quantile(0.75)\n",
    "df['glucose'] = np.where(df['glucose'] > upper_limit, upper_limit, df['glucose'])\n",
    "df['glucose'] = np.where(df['glucose'] < lower_limit, lower_limit, df['glucose'])\n",
    "\n",
    "print_and_visualize_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dc7812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to evalute F1 score, Confusion Matrix and Classification report:-\n",
    "\n",
    "def evalute_model(actual, predict):\n",
    "    score = accuracy_score(actual, predict) \n",
    "    f1 = f1_score(actual, predict)\n",
    "    report = classification_report(actual, predict)\n",
    "    matrix = confusion_matrix(actual, predict)\n",
    "    print(f'accuracy score:{score} \\n F1 Score: {f1} \\n Classification report:\\n {report} \\n Confusion matrix \\n {matrix}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac1d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Heart-Att']) # feature columns\n",
    "y= df['Heart-Att'] # target column\n",
    "\n",
    "# helper method to split dataset into training and test data \n",
    "def split_dataset(test_size):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_dataset(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e062802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using DecisionTreeClassifier algorithm\n",
    "model=DecisionTreeClassifier(random_state=42, max_depth=5, min_samples_split=5, min_samples_leaf=5)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# evalute the model for test and training data:\n",
    "print ('model evalute results for test data \\n')\n",
    "evalute_model(y_test, model.predict(X_test))\n",
    "\n",
    "print ('\\n model evalute results for training data \\n')\n",
    "evalute_model(y_train, model.predict(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3aea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using naive bayes(MultinomialNB) algorithm:-\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "# evalute the model for test and training data:\n",
    "print ('model evalute results for test data \\n')\n",
    "evalute_model(y_test, mnb.predict(X_test))\n",
    "\n",
    "print ('\\n model evalute results for training data')\n",
    "evalute_model(y_train, mnb.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3719fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Form above, DecisionTreeClassifier is best as comapared to naive bayes because \n",
    "accuracy for tree for test data is 84 % while for naive bayes is 77 %\n",
    "and for training data tree accuracy is 85 % while for naive bayes is 78%\n",
    "\n",
    "confusion matrix represent the false positive, true positive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
